[
    {
        "label": "op",
        "importPath": "alembic",
        "description": "alembic",
        "isExtraImport": true,
        "detail": "alembic",
        "documentation": {}
    },
    {
        "label": "op",
        "importPath": "alembic",
        "description": "alembic",
        "isExtraImport": true,
        "detail": "alembic",
        "documentation": {}
    },
    {
        "label": "op",
        "importPath": "alembic",
        "description": "alembic",
        "isExtraImport": true,
        "detail": "alembic",
        "documentation": {}
    },
    {
        "label": "context",
        "importPath": "alembic",
        "description": "alembic",
        "isExtraImport": true,
        "detail": "alembic",
        "documentation": {}
    },
    {
        "label": "sqlalchemy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "sqlalchemy",
        "description": "sqlalchemy",
        "detail": "sqlalchemy",
        "documentation": {}
    },
    {
        "label": "desc",
        "importPath": "sqlalchemy",
        "description": "sqlalchemy",
        "isExtraImport": true,
        "detail": "sqlalchemy",
        "documentation": {}
    },
    {
        "label": "logging",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "logging",
        "description": "logging",
        "detail": "logging",
        "documentation": {}
    },
    {
        "label": "fileConfig",
        "importPath": "logging.config",
        "description": "logging.config",
        "isExtraImport": true,
        "detail": "logging.config",
        "documentation": {}
    },
    {
        "label": "current_app",
        "importPath": "flask",
        "description": "flask",
        "isExtraImport": true,
        "detail": "flask",
        "documentation": {}
    },
    {
        "label": "Flask",
        "importPath": "flask",
        "description": "flask",
        "isExtraImport": true,
        "detail": "flask",
        "documentation": {}
    },
    {
        "label": "send_from_directory",
        "importPath": "flask",
        "description": "flask",
        "isExtraImport": true,
        "detail": "flask",
        "documentation": {}
    },
    {
        "label": "jsonify",
        "importPath": "flask",
        "description": "flask",
        "isExtraImport": true,
        "detail": "flask",
        "documentation": {}
    },
    {
        "label": "request",
        "importPath": "flask",
        "description": "flask",
        "isExtraImport": true,
        "detail": "flask",
        "documentation": {}
    },
    {
        "label": "request",
        "importPath": "flask",
        "description": "flask",
        "isExtraImport": true,
        "detail": "flask",
        "documentation": {}
    },
    {
        "label": "jsonify",
        "importPath": "flask",
        "description": "flask",
        "isExtraImport": true,
        "detail": "flask",
        "documentation": {}
    },
    {
        "label": "SQLAlchemy",
        "importPath": "flask_sqlalchemy",
        "description": "flask_sqlalchemy",
        "isExtraImport": true,
        "detail": "flask_sqlalchemy",
        "documentation": {}
    },
    {
        "label": "SQLAlchemy",
        "importPath": "flask_sqlalchemy",
        "description": "flask_sqlalchemy",
        "isExtraImport": true,
        "detail": "flask_sqlalchemy",
        "documentation": {}
    },
    {
        "label": "CORS",
        "importPath": "flask_cors",
        "description": "flask_cors",
        "isExtraImport": true,
        "detail": "flask_cors",
        "documentation": {}
    },
    {
        "label": "os",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os",
        "description": "os",
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "routes",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "routes",
        "description": "routes",
        "detail": "routes",
        "documentation": {}
    },
    {
        "label": "Migrate",
        "importPath": "flask_migrate",
        "description": "flask_migrate",
        "isExtraImport": true,
        "detail": "flask_migrate",
        "documentation": {}
    },
    {
        "label": "db",
        "importPath": "app",
        "description": "app",
        "isExtraImport": true,
        "detail": "app",
        "documentation": {}
    },
    {
        "label": "app",
        "importPath": "app",
        "description": "app",
        "isExtraImport": true,
        "detail": "app",
        "documentation": {}
    },
    {
        "label": "db",
        "importPath": "app",
        "description": "app",
        "isExtraImport": true,
        "detail": "app",
        "documentation": {}
    },
    {
        "label": "app",
        "importPath": "app",
        "description": "app",
        "isExtraImport": true,
        "detail": "app",
        "documentation": {}
    },
    {
        "label": "json",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "json",
        "description": "json",
        "detail": "json",
        "documentation": {}
    },
    {
        "label": "datetime",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "datetime",
        "description": "datetime",
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "Friend",
        "importPath": "models",
        "description": "models",
        "isExtraImport": true,
        "detail": "models",
        "documentation": {}
    },
    {
        "label": "Model",
        "importPath": "models",
        "description": "models",
        "isExtraImport": true,
        "detail": "models",
        "documentation": {}
    },
    {
        "label": "Feature",
        "importPath": "models",
        "description": "models",
        "isExtraImport": true,
        "detail": "models",
        "documentation": {}
    },
    {
        "label": "joblib",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "joblib",
        "description": "joblib",
        "detail": "joblib",
        "documentation": {}
    },
    {
        "label": "sklearn",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "sklearn",
        "description": "sklearn",
        "detail": "sklearn",
        "documentation": {}
    },
    {
        "label": "wraps",
        "importPath": "functools",
        "description": "functools",
        "isExtraImport": true,
        "detail": "functools",
        "documentation": {}
    },
    {
        "label": "stringify",
        "importPath": "flatted",
        "description": "flatted",
        "isExtraImport": true,
        "detail": "flatted",
        "documentation": {}
    },
    {
        "label": "parse",
        "importPath": "flatted",
        "description": "flatted",
        "isExtraImport": true,
        "detail": "flatted",
        "documentation": {}
    },
    {
        "label": "upgrade",
        "kind": 2,
        "importPath": "backend.migrations.versions.7115af7ba495_initial_migration",
        "description": "backend.migrations.versions.7115af7ba495_initial_migration",
        "peekOfCode": "def upgrade():\n    # ### commands auto generated by Alembic - please adjust! ###\n    with op.batch_alter_table('model', schema=None) as batch_op:\n        batch_op.drop_column('calculatefeatures')\n    # ### end Alembic commands ###\ndef downgrade():\n    # ### commands auto generated by Alembic - please adjust! ###\n    with op.batch_alter_table('model', schema=None) as batch_op:\n        batch_op.add_column(sa.Column('calculatefeatures', sa.TEXT(), nullable=False))\n    # ### end Alembic commands ###",
        "detail": "backend.migrations.versions.7115af7ba495_initial_migration",
        "documentation": {}
    },
    {
        "label": "downgrade",
        "kind": 2,
        "importPath": "backend.migrations.versions.7115af7ba495_initial_migration",
        "description": "backend.migrations.versions.7115af7ba495_initial_migration",
        "peekOfCode": "def downgrade():\n    # ### commands auto generated by Alembic - please adjust! ###\n    with op.batch_alter_table('model', schema=None) as batch_op:\n        batch_op.add_column(sa.Column('calculatefeatures', sa.TEXT(), nullable=False))\n    # ### end Alembic commands ###",
        "detail": "backend.migrations.versions.7115af7ba495_initial_migration",
        "documentation": {}
    },
    {
        "label": "revision",
        "kind": 5,
        "importPath": "backend.migrations.versions.7115af7ba495_initial_migration",
        "description": "backend.migrations.versions.7115af7ba495_initial_migration",
        "peekOfCode": "revision = '7115af7ba495'\ndown_revision = 'b7d73ef92b25'\nbranch_labels = None\ndepends_on = None\ndef upgrade():\n    # ### commands auto generated by Alembic - please adjust! ###\n    with op.batch_alter_table('model', schema=None) as batch_op:\n        batch_op.drop_column('calculatefeatures')\n    # ### end Alembic commands ###\ndef downgrade():",
        "detail": "backend.migrations.versions.7115af7ba495_initial_migration",
        "documentation": {}
    },
    {
        "label": "down_revision",
        "kind": 5,
        "importPath": "backend.migrations.versions.7115af7ba495_initial_migration",
        "description": "backend.migrations.versions.7115af7ba495_initial_migration",
        "peekOfCode": "down_revision = 'b7d73ef92b25'\nbranch_labels = None\ndepends_on = None\ndef upgrade():\n    # ### commands auto generated by Alembic - please adjust! ###\n    with op.batch_alter_table('model', schema=None) as batch_op:\n        batch_op.drop_column('calculatefeatures')\n    # ### end Alembic commands ###\ndef downgrade():\n    # ### commands auto generated by Alembic - please adjust! ###",
        "detail": "backend.migrations.versions.7115af7ba495_initial_migration",
        "documentation": {}
    },
    {
        "label": "branch_labels",
        "kind": 5,
        "importPath": "backend.migrations.versions.7115af7ba495_initial_migration",
        "description": "backend.migrations.versions.7115af7ba495_initial_migration",
        "peekOfCode": "branch_labels = None\ndepends_on = None\ndef upgrade():\n    # ### commands auto generated by Alembic - please adjust! ###\n    with op.batch_alter_table('model', schema=None) as batch_op:\n        batch_op.drop_column('calculatefeatures')\n    # ### end Alembic commands ###\ndef downgrade():\n    # ### commands auto generated by Alembic - please adjust! ###\n    with op.batch_alter_table('model', schema=None) as batch_op:",
        "detail": "backend.migrations.versions.7115af7ba495_initial_migration",
        "documentation": {}
    },
    {
        "label": "depends_on",
        "kind": 5,
        "importPath": "backend.migrations.versions.7115af7ba495_initial_migration",
        "description": "backend.migrations.versions.7115af7ba495_initial_migration",
        "peekOfCode": "depends_on = None\ndef upgrade():\n    # ### commands auto generated by Alembic - please adjust! ###\n    with op.batch_alter_table('model', schema=None) as batch_op:\n        batch_op.drop_column('calculatefeatures')\n    # ### end Alembic commands ###\ndef downgrade():\n    # ### commands auto generated by Alembic - please adjust! ###\n    with op.batch_alter_table('model', schema=None) as batch_op:\n        batch_op.add_column(sa.Column('calculatefeatures', sa.TEXT(), nullable=False))",
        "detail": "backend.migrations.versions.7115af7ba495_initial_migration",
        "documentation": {}
    },
    {
        "label": "upgrade",
        "kind": 2,
        "importPath": "backend.migrations.versions.b5bca021e0e5_add_some_extra_file_feilds",
        "description": "backend.migrations.versions.b5bca021e0e5_add_some_extra_file_feilds",
        "peekOfCode": "def upgrade():\n    # ### commands auto generated by Alembic - please adjust! ###\n    op.drop_table('_alembic_tmp_model')\n    with op.batch_alter_table('model', schema=None) as batch_op:\n        batch_op.add_column(sa.Column('scalerfile', sa.String(length=255), nullable=True))\n        batch_op.add_column(sa.Column('encodingfile', sa.String(length=255), nullable=True))\n        batch_op.alter_column('filename',\n               existing_type=sa.VARCHAR(length=100),\n               type_=sa.String(length=255),\n               existing_nullable=False)",
        "detail": "backend.migrations.versions.b5bca021e0e5_add_some_extra_file_feilds",
        "documentation": {}
    },
    {
        "label": "downgrade",
        "kind": 2,
        "importPath": "backend.migrations.versions.b5bca021e0e5_add_some_extra_file_feilds",
        "description": "backend.migrations.versions.b5bca021e0e5_add_some_extra_file_feilds",
        "peekOfCode": "def downgrade():\n    # ### commands auto generated by Alembic - please adjust! ###\n    with op.batch_alter_table('model', schema=None) as batch_op:\n        batch_op.alter_column('filename',\n               existing_type=sa.String(length=255),\n               type_=sa.VARCHAR(length=100),\n               existing_nullable=False)\n        batch_op.drop_column('encodingfile')\n        batch_op.drop_column('scalerfile')\n    op.create_table('_alembic_tmp_model',",
        "detail": "backend.migrations.versions.b5bca021e0e5_add_some_extra_file_feilds",
        "documentation": {}
    },
    {
        "label": "revision",
        "kind": 5,
        "importPath": "backend.migrations.versions.b5bca021e0e5_add_some_extra_file_feilds",
        "description": "backend.migrations.versions.b5bca021e0e5_add_some_extra_file_feilds",
        "peekOfCode": "revision = 'b5bca021e0e5'\ndown_revision = '7115af7ba495'\nbranch_labels = None\ndepends_on = None\ndef upgrade():\n    # ### commands auto generated by Alembic - please adjust! ###\n    op.drop_table('_alembic_tmp_model')\n    with op.batch_alter_table('model', schema=None) as batch_op:\n        batch_op.add_column(sa.Column('scalerfile', sa.String(length=255), nullable=True))\n        batch_op.add_column(sa.Column('encodingfile', sa.String(length=255), nullable=True))",
        "detail": "backend.migrations.versions.b5bca021e0e5_add_some_extra_file_feilds",
        "documentation": {}
    },
    {
        "label": "down_revision",
        "kind": 5,
        "importPath": "backend.migrations.versions.b5bca021e0e5_add_some_extra_file_feilds",
        "description": "backend.migrations.versions.b5bca021e0e5_add_some_extra_file_feilds",
        "peekOfCode": "down_revision = '7115af7ba495'\nbranch_labels = None\ndepends_on = None\ndef upgrade():\n    # ### commands auto generated by Alembic - please adjust! ###\n    op.drop_table('_alembic_tmp_model')\n    with op.batch_alter_table('model', schema=None) as batch_op:\n        batch_op.add_column(sa.Column('scalerfile', sa.String(length=255), nullable=True))\n        batch_op.add_column(sa.Column('encodingfile', sa.String(length=255), nullable=True))\n        batch_op.alter_column('filename',",
        "detail": "backend.migrations.versions.b5bca021e0e5_add_some_extra_file_feilds",
        "documentation": {}
    },
    {
        "label": "branch_labels",
        "kind": 5,
        "importPath": "backend.migrations.versions.b5bca021e0e5_add_some_extra_file_feilds",
        "description": "backend.migrations.versions.b5bca021e0e5_add_some_extra_file_feilds",
        "peekOfCode": "branch_labels = None\ndepends_on = None\ndef upgrade():\n    # ### commands auto generated by Alembic - please adjust! ###\n    op.drop_table('_alembic_tmp_model')\n    with op.batch_alter_table('model', schema=None) as batch_op:\n        batch_op.add_column(sa.Column('scalerfile', sa.String(length=255), nullable=True))\n        batch_op.add_column(sa.Column('encodingfile', sa.String(length=255), nullable=True))\n        batch_op.alter_column('filename',\n               existing_type=sa.VARCHAR(length=100),",
        "detail": "backend.migrations.versions.b5bca021e0e5_add_some_extra_file_feilds",
        "documentation": {}
    },
    {
        "label": "depends_on",
        "kind": 5,
        "importPath": "backend.migrations.versions.b5bca021e0e5_add_some_extra_file_feilds",
        "description": "backend.migrations.versions.b5bca021e0e5_add_some_extra_file_feilds",
        "peekOfCode": "depends_on = None\ndef upgrade():\n    # ### commands auto generated by Alembic - please adjust! ###\n    op.drop_table('_alembic_tmp_model')\n    with op.batch_alter_table('model', schema=None) as batch_op:\n        batch_op.add_column(sa.Column('scalerfile', sa.String(length=255), nullable=True))\n        batch_op.add_column(sa.Column('encodingfile', sa.String(length=255), nullable=True))\n        batch_op.alter_column('filename',\n               existing_type=sa.VARCHAR(length=100),\n               type_=sa.String(length=255),",
        "detail": "backend.migrations.versions.b5bca021e0e5_add_some_extra_file_feilds",
        "documentation": {}
    },
    {
        "label": "upgrade",
        "kind": 2,
        "importPath": "backend.migrations.versions.b7d73ef92b25_initial_migration",
        "description": "backend.migrations.versions.b7d73ef92b25_initial_migration",
        "peekOfCode": "def upgrade():\n    # ### commands auto generated by Alembic - please adjust! ###\n    op.create_table('feature',\n    sa.Column('id', sa.Integer(), nullable=False),\n    sa.Column('name', sa.String(length=100), nullable=False),\n    sa.Column('datatype', sa.String(length=50), nullable=False),\n    sa.Column('description', sa.Text(), nullable=True),\n    sa.PrimaryKeyConstraint('id')\n    )\n    op.create_table('friend',",
        "detail": "backend.migrations.versions.b7d73ef92b25_initial_migration",
        "documentation": {}
    },
    {
        "label": "downgrade",
        "kind": 2,
        "importPath": "backend.migrations.versions.b7d73ef92b25_initial_migration",
        "description": "backend.migrations.versions.b7d73ef92b25_initial_migration",
        "peekOfCode": "def downgrade():\n    # ### commands auto generated by Alembic - please adjust! ###\n    op.drop_table('model')\n    op.drop_table('friend')\n    op.drop_table('feature')\n    # ### end Alembic commands ###",
        "detail": "backend.migrations.versions.b7d73ef92b25_initial_migration",
        "documentation": {}
    },
    {
        "label": "revision",
        "kind": 5,
        "importPath": "backend.migrations.versions.b7d73ef92b25_initial_migration",
        "description": "backend.migrations.versions.b7d73ef92b25_initial_migration",
        "peekOfCode": "revision = 'b7d73ef92b25'\ndown_revision = None\nbranch_labels = None\ndepends_on = None\ndef upgrade():\n    # ### commands auto generated by Alembic - please adjust! ###\n    op.create_table('feature',\n    sa.Column('id', sa.Integer(), nullable=False),\n    sa.Column('name', sa.String(length=100), nullable=False),\n    sa.Column('datatype', sa.String(length=50), nullable=False),",
        "detail": "backend.migrations.versions.b7d73ef92b25_initial_migration",
        "documentation": {}
    },
    {
        "label": "down_revision",
        "kind": 5,
        "importPath": "backend.migrations.versions.b7d73ef92b25_initial_migration",
        "description": "backend.migrations.versions.b7d73ef92b25_initial_migration",
        "peekOfCode": "down_revision = None\nbranch_labels = None\ndepends_on = None\ndef upgrade():\n    # ### commands auto generated by Alembic - please adjust! ###\n    op.create_table('feature',\n    sa.Column('id', sa.Integer(), nullable=False),\n    sa.Column('name', sa.String(length=100), nullable=False),\n    sa.Column('datatype', sa.String(length=50), nullable=False),\n    sa.Column('description', sa.Text(), nullable=True),",
        "detail": "backend.migrations.versions.b7d73ef92b25_initial_migration",
        "documentation": {}
    },
    {
        "label": "branch_labels",
        "kind": 5,
        "importPath": "backend.migrations.versions.b7d73ef92b25_initial_migration",
        "description": "backend.migrations.versions.b7d73ef92b25_initial_migration",
        "peekOfCode": "branch_labels = None\ndepends_on = None\ndef upgrade():\n    # ### commands auto generated by Alembic - please adjust! ###\n    op.create_table('feature',\n    sa.Column('id', sa.Integer(), nullable=False),\n    sa.Column('name', sa.String(length=100), nullable=False),\n    sa.Column('datatype', sa.String(length=50), nullable=False),\n    sa.Column('description', sa.Text(), nullable=True),\n    sa.PrimaryKeyConstraint('id')",
        "detail": "backend.migrations.versions.b7d73ef92b25_initial_migration",
        "documentation": {}
    },
    {
        "label": "depends_on",
        "kind": 5,
        "importPath": "backend.migrations.versions.b7d73ef92b25_initial_migration",
        "description": "backend.migrations.versions.b7d73ef92b25_initial_migration",
        "peekOfCode": "depends_on = None\ndef upgrade():\n    # ### commands auto generated by Alembic - please adjust! ###\n    op.create_table('feature',\n    sa.Column('id', sa.Integer(), nullable=False),\n    sa.Column('name', sa.String(length=100), nullable=False),\n    sa.Column('datatype', sa.String(length=50), nullable=False),\n    sa.Column('description', sa.Text(), nullable=True),\n    sa.PrimaryKeyConstraint('id')\n    )",
        "detail": "backend.migrations.versions.b7d73ef92b25_initial_migration",
        "documentation": {}
    },
    {
        "label": "get_engine",
        "kind": 2,
        "importPath": "backend.migrations.env",
        "description": "backend.migrations.env",
        "peekOfCode": "def get_engine():\n    try:\n        # this works with Flask-SQLAlchemy<3 and Alchemical\n        return current_app.extensions['migrate'].db.get_engine()\n    except (TypeError, AttributeError):\n        # this works with Flask-SQLAlchemy>=3\n        return current_app.extensions['migrate'].db.engine\ndef get_engine_url():\n    try:\n        return get_engine().url.render_as_string(hide_password=False).replace(",
        "detail": "backend.migrations.env",
        "documentation": {}
    },
    {
        "label": "get_engine_url",
        "kind": 2,
        "importPath": "backend.migrations.env",
        "description": "backend.migrations.env",
        "peekOfCode": "def get_engine_url():\n    try:\n        return get_engine().url.render_as_string(hide_password=False).replace(\n            '%', '%%')\n    except AttributeError:\n        return str(get_engine().url).replace('%', '%%')\n# add your model's MetaData object here\n# for 'autogenerate' support\n# from myapp import mymodel\n# target_metadata = mymodel.Base.metadata",
        "detail": "backend.migrations.env",
        "documentation": {}
    },
    {
        "label": "get_metadata",
        "kind": 2,
        "importPath": "backend.migrations.env",
        "description": "backend.migrations.env",
        "peekOfCode": "def get_metadata():\n    if hasattr(target_db, 'metadatas'):\n        return target_db.metadatas[None]\n    return target_db.metadata\ndef run_migrations_offline():\n    \"\"\"Run migrations in 'offline' mode.\n    This configures the context with just a URL\n    and not an Engine, though an Engine is acceptable\n    here as well.  By skipping the Engine creation\n    we don't even need a DBAPI to be available.",
        "detail": "backend.migrations.env",
        "documentation": {}
    },
    {
        "label": "run_migrations_offline",
        "kind": 2,
        "importPath": "backend.migrations.env",
        "description": "backend.migrations.env",
        "peekOfCode": "def run_migrations_offline():\n    \"\"\"Run migrations in 'offline' mode.\n    This configures the context with just a URL\n    and not an Engine, though an Engine is acceptable\n    here as well.  By skipping the Engine creation\n    we don't even need a DBAPI to be available.\n    Calls to context.execute() here emit the given string to the\n    script output.\n    \"\"\"\n    url = config.get_main_option(\"sqlalchemy.url\")",
        "detail": "backend.migrations.env",
        "documentation": {}
    },
    {
        "label": "run_migrations_online",
        "kind": 2,
        "importPath": "backend.migrations.env",
        "description": "backend.migrations.env",
        "peekOfCode": "def run_migrations_online():\n    \"\"\"Run migrations in 'online' mode.\n    In this scenario we need to create an Engine\n    and associate a connection with the context.\n    \"\"\"\n    # this callback is used to prevent an auto-migration from being generated\n    # when there are no changes to the schema\n    # reference: http://alembic.zzzcomputing.com/en/latest/cookbook.html\n    def process_revision_directives(context, revision, directives):\n        if getattr(config.cmd_opts, 'autogenerate', False):",
        "detail": "backend.migrations.env",
        "documentation": {}
    },
    {
        "label": "config",
        "kind": 5,
        "importPath": "backend.migrations.env",
        "description": "backend.migrations.env",
        "peekOfCode": "config = context.config\n# Interpret the config file for Python logging.\n# This line sets up loggers basically.\nfileConfig(config.config_file_name)\nlogger = logging.getLogger('alembic.env')\ndef get_engine():\n    try:\n        # this works with Flask-SQLAlchemy<3 and Alchemical\n        return current_app.extensions['migrate'].db.get_engine()\n    except (TypeError, AttributeError):",
        "detail": "backend.migrations.env",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "backend.migrations.env",
        "description": "backend.migrations.env",
        "peekOfCode": "logger = logging.getLogger('alembic.env')\ndef get_engine():\n    try:\n        # this works with Flask-SQLAlchemy<3 and Alchemical\n        return current_app.extensions['migrate'].db.get_engine()\n    except (TypeError, AttributeError):\n        # this works with Flask-SQLAlchemy>=3\n        return current_app.extensions['migrate'].db.engine\ndef get_engine_url():\n    try:",
        "detail": "backend.migrations.env",
        "documentation": {}
    },
    {
        "label": "target_db",
        "kind": 5,
        "importPath": "backend.migrations.env",
        "description": "backend.migrations.env",
        "peekOfCode": "target_db = current_app.extensions['migrate'].db\n# other values from the config, defined by the needs of env.py,\n# can be acquired:\n# my_important_option = config.get_main_option(\"my_important_option\")\n# ... etc.\ndef get_metadata():\n    if hasattr(target_db, 'metadatas'):\n        return target_db.metadatas[None]\n    return target_db.metadata\ndef run_migrations_offline():",
        "detail": "backend.migrations.env",
        "documentation": {}
    },
    {
        "label": "get_heatmap_image",
        "kind": 2,
        "importPath": "backend.app",
        "description": "backend.app",
        "peekOfCode": "def get_heatmap_image(filename):\n    return send_from_directory(app.config['HEATMAP_FILES'], filename)\n# Serve static files\n@app.route(\"/\", defaults={\"filename\": \"\"})\n@app.route(\"/<path:filename>\")\ndef index(filename):\n    if not filename:\n        filename = \"index.html\"\n    return send_from_directory(dist_folder, filename)\n# Import API routes",
        "detail": "backend.app",
        "documentation": {}
    },
    {
        "label": "index",
        "kind": 2,
        "importPath": "backend.app",
        "description": "backend.app",
        "peekOfCode": "def index(filename):\n    if not filename:\n        filename = \"index.html\"\n    return send_from_directory(dist_folder, filename)\n# Import API routes\nimport routes\n# Initialize database migrations\nfrom flask_migrate import Migrate\nmigrate = Migrate(app, db)\n# Error handling",
        "detail": "backend.app",
        "documentation": {}
    },
    {
        "label": "page_not_found",
        "kind": 2,
        "importPath": "backend.app",
        "description": "backend.app",
        "peekOfCode": "def page_not_found(error):\n    return jsonify({\"error\": \"Page not found\"}), 404\n@app.errorhandler(500)\ndef internal_server_error(error):\n    return jsonify({\"error\": \"Internal server error\"}), 500\n# Only run the app if this file is executed directly\nif __name__ == \"__main__\":\n    app.run(debug=False)",
        "detail": "backend.app",
        "documentation": {}
    },
    {
        "label": "internal_server_error",
        "kind": 2,
        "importPath": "backend.app",
        "description": "backend.app",
        "peekOfCode": "def internal_server_error(error):\n    return jsonify({\"error\": \"Internal server error\"}), 500\n# Only run the app if this file is executed directly\nif __name__ == \"__main__\":\n    app.run(debug=False)",
        "detail": "backend.app",
        "documentation": {}
    },
    {
        "label": "app",
        "kind": 5,
        "importPath": "backend.app",
        "description": "backend.app",
        "peekOfCode": "app = Flask(__name__)\n# Configure CORS\n# Comment out or configure properly if not needed in production\nCORS(app, resources={r\"/api/*\": {\"origins\": \"*\"}})\n# Configure the database (update URI for production as needed)\napp.config['SQLALCHEMY_DATABASE_URI'] = os.getenv('DATABASE_URL', 'sqlite:///models.db')\napp.config[\"SQLALCHEMY_TRACK_MODIFICATIONS\"] = False\napp.config['MODEL_FILES'] = 'modelFiles'\napp.config['SCALER_FILES'] = 'scalerFiles'\napp.config['ENCODING_FILES'] = 'encodingFiles'",
        "detail": "backend.app",
        "documentation": {}
    },
    {
        "label": "app.config['SQLALCHEMY_DATABASE_URI']",
        "kind": 5,
        "importPath": "backend.app",
        "description": "backend.app",
        "peekOfCode": "app.config['SQLALCHEMY_DATABASE_URI'] = os.getenv('DATABASE_URL', 'sqlite:///models.db')\napp.config[\"SQLALCHEMY_TRACK_MODIFICATIONS\"] = False\napp.config['MODEL_FILES'] = 'modelFiles'\napp.config['SCALER_FILES'] = 'scalerFiles'\napp.config['ENCODING_FILES'] = 'encodingFiles'\napp.config['HEATMAP_FILES'] = 'heatmaps'\ndb = SQLAlchemy(app)\n# Define the paths for your frontend static files\nfrontend_folder = os.path.join(os.getcwd(), \"..\", \"frontend\")\ndist_folder = os.path.join(frontend_folder, \"dist\")",
        "detail": "backend.app",
        "documentation": {}
    },
    {
        "label": "app.config[\"SQLALCHEMY_TRACK_MODIFICATIONS\"]",
        "kind": 5,
        "importPath": "backend.app",
        "description": "backend.app",
        "peekOfCode": "app.config[\"SQLALCHEMY_TRACK_MODIFICATIONS\"] = False\napp.config['MODEL_FILES'] = 'modelFiles'\napp.config['SCALER_FILES'] = 'scalerFiles'\napp.config['ENCODING_FILES'] = 'encodingFiles'\napp.config['HEATMAP_FILES'] = 'heatmaps'\ndb = SQLAlchemy(app)\n# Define the paths for your frontend static files\nfrontend_folder = os.path.join(os.getcwd(), \"..\", \"frontend\")\ndist_folder = os.path.join(frontend_folder, \"dist\")\n# Serve heatmap images",
        "detail": "backend.app",
        "documentation": {}
    },
    {
        "label": "app.config['MODEL_FILES']",
        "kind": 5,
        "importPath": "backend.app",
        "description": "backend.app",
        "peekOfCode": "app.config['MODEL_FILES'] = 'modelFiles'\napp.config['SCALER_FILES'] = 'scalerFiles'\napp.config['ENCODING_FILES'] = 'encodingFiles'\napp.config['HEATMAP_FILES'] = 'heatmaps'\ndb = SQLAlchemy(app)\n# Define the paths for your frontend static files\nfrontend_folder = os.path.join(os.getcwd(), \"..\", \"frontend\")\ndist_folder = os.path.join(frontend_folder, \"dist\")\n# Serve heatmap images\n@app.route('/api/heatmaps/<filename>')",
        "detail": "backend.app",
        "documentation": {}
    },
    {
        "label": "app.config['SCALER_FILES']",
        "kind": 5,
        "importPath": "backend.app",
        "description": "backend.app",
        "peekOfCode": "app.config['SCALER_FILES'] = 'scalerFiles'\napp.config['ENCODING_FILES'] = 'encodingFiles'\napp.config['HEATMAP_FILES'] = 'heatmaps'\ndb = SQLAlchemy(app)\n# Define the paths for your frontend static files\nfrontend_folder = os.path.join(os.getcwd(), \"..\", \"frontend\")\ndist_folder = os.path.join(frontend_folder, \"dist\")\n# Serve heatmap images\n@app.route('/api/heatmaps/<filename>')\ndef get_heatmap_image(filename):",
        "detail": "backend.app",
        "documentation": {}
    },
    {
        "label": "app.config['ENCODING_FILES']",
        "kind": 5,
        "importPath": "backend.app",
        "description": "backend.app",
        "peekOfCode": "app.config['ENCODING_FILES'] = 'encodingFiles'\napp.config['HEATMAP_FILES'] = 'heatmaps'\ndb = SQLAlchemy(app)\n# Define the paths for your frontend static files\nfrontend_folder = os.path.join(os.getcwd(), \"..\", \"frontend\")\ndist_folder = os.path.join(frontend_folder, \"dist\")\n# Serve heatmap images\n@app.route('/api/heatmaps/<filename>')\ndef get_heatmap_image(filename):\n    return send_from_directory(app.config['HEATMAP_FILES'], filename)",
        "detail": "backend.app",
        "documentation": {}
    },
    {
        "label": "app.config['HEATMAP_FILES']",
        "kind": 5,
        "importPath": "backend.app",
        "description": "backend.app",
        "peekOfCode": "app.config['HEATMAP_FILES'] = 'heatmaps'\ndb = SQLAlchemy(app)\n# Define the paths for your frontend static files\nfrontend_folder = os.path.join(os.getcwd(), \"..\", \"frontend\")\ndist_folder = os.path.join(frontend_folder, \"dist\")\n# Serve heatmap images\n@app.route('/api/heatmaps/<filename>')\ndef get_heatmap_image(filename):\n    return send_from_directory(app.config['HEATMAP_FILES'], filename)\n# Serve static files",
        "detail": "backend.app",
        "documentation": {}
    },
    {
        "label": "db",
        "kind": 5,
        "importPath": "backend.app",
        "description": "backend.app",
        "peekOfCode": "db = SQLAlchemy(app)\n# Define the paths for your frontend static files\nfrontend_folder = os.path.join(os.getcwd(), \"..\", \"frontend\")\ndist_folder = os.path.join(frontend_folder, \"dist\")\n# Serve heatmap images\n@app.route('/api/heatmaps/<filename>')\ndef get_heatmap_image(filename):\n    return send_from_directory(app.config['HEATMAP_FILES'], filename)\n# Serve static files\n@app.route(\"/\", defaults={\"filename\": \"\"})",
        "detail": "backend.app",
        "documentation": {}
    },
    {
        "label": "frontend_folder",
        "kind": 5,
        "importPath": "backend.app",
        "description": "backend.app",
        "peekOfCode": "frontend_folder = os.path.join(os.getcwd(), \"..\", \"frontend\")\ndist_folder = os.path.join(frontend_folder, \"dist\")\n# Serve heatmap images\n@app.route('/api/heatmaps/<filename>')\ndef get_heatmap_image(filename):\n    return send_from_directory(app.config['HEATMAP_FILES'], filename)\n# Serve static files\n@app.route(\"/\", defaults={\"filename\": \"\"})\n@app.route(\"/<path:filename>\")\ndef index(filename):",
        "detail": "backend.app",
        "documentation": {}
    },
    {
        "label": "dist_folder",
        "kind": 5,
        "importPath": "backend.app",
        "description": "backend.app",
        "peekOfCode": "dist_folder = os.path.join(frontend_folder, \"dist\")\n# Serve heatmap images\n@app.route('/api/heatmaps/<filename>')\ndef get_heatmap_image(filename):\n    return send_from_directory(app.config['HEATMAP_FILES'], filename)\n# Serve static files\n@app.route(\"/\", defaults={\"filename\": \"\"})\n@app.route(\"/<path:filename>\")\ndef index(filename):\n    if not filename:",
        "detail": "backend.app",
        "documentation": {}
    },
    {
        "label": "migrate",
        "kind": 5,
        "importPath": "backend.app",
        "description": "backend.app",
        "peekOfCode": "migrate = Migrate(app, db)\n# Error handling\n@app.errorhandler(404)\ndef page_not_found(error):\n    return jsonify({\"error\": \"Page not found\"}), 404\n@app.errorhandler(500)\ndef internal_server_error(error):\n    return jsonify({\"error\": \"Internal server error\"}), 500\n# Only run the app if this file is executed directly\nif __name__ == \"__main__\":",
        "detail": "backend.app",
        "documentation": {}
    },
    {
        "label": "Friend",
        "kind": 6,
        "importPath": "backend.models",
        "description": "backend.models",
        "peekOfCode": "class Friend(db.Model):\n  id = db.Column(db.Integer, primary_key=True)\n  name = db.Column(db.String(100), nullable=False)\n  role = db.Column(db.String(50), nullable=False)\n  description = db.Column(db.Text, nullable=False)\n  gender = db.Column(db.String(10), nullable=False)\n  img_url = db.Column(db.String(200), nullable=True)\n  def to_json(self):\n    return {\n      \"id\":self.id,",
        "detail": "backend.models",
        "documentation": {}
    },
    {
        "label": "Feature",
        "kind": 6,
        "importPath": "backend.models",
        "description": "backend.models",
        "peekOfCode": "class Feature(db.Model):\n    id = db.Column(db.Integer, primary_key=True)\n    name = db.Column(db.String(100), nullable=False)\n    datatype = db.Column(db.String(50), nullable=False)\n    description = db.Column(db.Text, nullable=True)\nclass Model(db.Model):\n  id = db.Column(db.Integer, primary_key=True)\n  name = db.Column(db.String(100), nullable=False)\n  filename = db.Column(db.String(255), nullable=False)  # Increased length\n  scalerfile = db.Column(db.String(255), nullable=True)",
        "detail": "backend.models",
        "documentation": {}
    },
    {
        "label": "Model",
        "kind": 6,
        "importPath": "backend.models",
        "description": "backend.models",
        "peekOfCode": "class Model(db.Model):\n  id = db.Column(db.Integer, primary_key=True)\n  name = db.Column(db.String(100), nullable=False)\n  filename = db.Column(db.String(255), nullable=False)  # Increased length\n  scalerfile = db.Column(db.String(255), nullable=True)\n  encodingfile = db.Column(db.String(255), nullable=True)\n  about_dataset = db.Column(db.Text, nullable=False)\n  features = db.Column(db.Text, nullable=False)  # Store JSON as string\n  description = db.Column(db.Text, nullable=False)\n  heatmap_image = db.Column(db.String(200), nullable=True)",
        "detail": "backend.models",
        "documentation": {}
    },
    {
        "label": "check_password",
        "kind": 2,
        "importPath": "backend.routes",
        "description": "backend.routes",
        "peekOfCode": "def check_password(password):\n    return password == SECRET_PASSWORD\ndef require_password(f):\n    @wraps(f)\n    def decorated_function(*args, **kwargs):\n        # Get the password from the form data\n        password = request.form.get('password')\n        print(password)\n        # Check if the password is correct\n        if not check_password(password):",
        "detail": "backend.routes",
        "documentation": {}
    },
    {
        "label": "require_password",
        "kind": 2,
        "importPath": "backend.routes",
        "description": "backend.routes",
        "peekOfCode": "def require_password(f):\n    @wraps(f)\n    def decorated_function(*args, **kwargs):\n        # Get the password from the form data\n        password = request.form.get('password')\n        print(password)\n        # Check if the password is correct\n        if not check_password(password):\n            return jsonify({\"error\": \"Unauthorized\"}), 401\n        return f(*args, **kwargs)",
        "detail": "backend.routes",
        "documentation": {}
    },
    {
        "label": "get_friends",
        "kind": 2,
        "importPath": "backend.routes",
        "description": "backend.routes",
        "peekOfCode": "def get_friends():\n  friends = Friend.query.all() \n  result = [friend.to_json() for friend in friends]\n  return jsonify(result)\n# Create a friend\n@app.route(\"/api/friends\",methods=[\"POST\"])\ndef create_friend():\n  try:\n    data = request.json\n    # Validations",
        "detail": "backend.routes",
        "documentation": {}
    },
    {
        "label": "create_friend",
        "kind": 2,
        "importPath": "backend.routes",
        "description": "backend.routes",
        "peekOfCode": "def create_friend():\n  try:\n    data = request.json\n    # Validations\n    required_fields = [\"name\",\"role\",\"description\",\"gender\"]\n    for field in required_fields:\n      if field not in data or not data.get(field):\n        return jsonify({\"error\":f'Missing required field: {field}'}), 400\n    name = data.get(\"name\")\n    role = data.get(\"role\")",
        "detail": "backend.routes",
        "documentation": {}
    },
    {
        "label": "delete_friend",
        "kind": 2,
        "importPath": "backend.routes",
        "description": "backend.routes",
        "peekOfCode": "def delete_friend(id):\n  try:\n    friend = Friend.query.get(id)\n    if friend is None:\n      return jsonify({\"error\":\"Friend not found\"}), 404\n    db.session.delete(friend)\n    db.session.commit()\n    return jsonify({\"msg\":\"Friend deleted\"}), 200\n  except Exception as e:\n    db.session.rollback()",
        "detail": "backend.routes",
        "documentation": {}
    },
    {
        "label": "update_friend",
        "kind": 2,
        "importPath": "backend.routes",
        "description": "backend.routes",
        "peekOfCode": "def update_friend(id):\n  try:\n    friend = Friend.query.get(id)\n    if friend is None:\n      return jsonify({\"error\":\"Friend not found\"}), 404\n    data = request.json\n    friend.name = data.get(\"name\",friend.name)\n    friend.role = data.get(\"role\",friend.role)\n    friend.description = data.get(\"description\",friend.description)\n    friend.gender = data.get(\"gender\",friend.gender)",
        "detail": "backend.routes",
        "documentation": {}
    },
    {
        "label": "get_timestamped_filename",
        "kind": 2,
        "importPath": "backend.routes",
        "description": "backend.routes",
        "peekOfCode": "def get_timestamped_filename(filename):\n    # Extract the file extension and base name\n    base_name, file_ext = os.path.splitext(filename)\n    # Generate a timestamp\n    timestamp = datetime.now().strftime('%Y%m%d%H%M%S')\n    # Combine the base name with the timestamp and extension\n    return f\"{base_name}-{timestamp}{file_ext}\"\n@app.route(\"/api/models\", methods=[\"POST\"])\n@require_password\ndef create_model():",
        "detail": "backend.routes",
        "documentation": {}
    },
    {
        "label": "create_model",
        "kind": 2,
        "importPath": "backend.routes",
        "description": "backend.routes",
        "peekOfCode": "def create_model():\n    try:\n        # Check if files are present\n        if 'filename' not in request.files:\n            return jsonify({\"error\": \"Missing required file(s)\"}), 400\n        # Extract form data\n        name = request.form.get(\"name\")\n        description = request.form.get(\"description\")\n        about_dataset = request.form.get(\"about_dataset\")\n        best_algorithm = request.form.get(\"best_algorithm\")",
        "detail": "backend.routes",
        "documentation": {}
    },
    {
        "label": "get_models",
        "kind": 2,
        "importPath": "backend.routes",
        "description": "backend.routes",
        "peekOfCode": "def get_models():\n    try:\n        # Get pagination parameters from request\n        page = request.args.get('page', 1, type=int)  # Default to page 1 if not provided\n        per_page = request.args.get('per_page', 10, type=int)  # Default to 10 items per page\n        # Calculate offset and limit\n        offset = (page - 1) * per_page\n        limit = per_page\n        # Query with offset and limit\n        total_count = db.session.query(Model).count()  # Get total count of models",
        "detail": "backend.routes",
        "documentation": {}
    },
    {
        "label": "get_model",
        "kind": 2,
        "importPath": "backend.routes",
        "description": "backend.routes",
        "peekOfCode": "def get_model(id):\n    try:\n        # Query the model by ID\n        model = Model.query.get(id)\n        if model is None:\n            return jsonify({\"error\": \"Model not found\"}), 404\n        return jsonify(model.to_json()), 200\n    except Exception as e:\n        print(\"Error:\", str(e))  # For debugging; remove or handle properly in production\n        return jsonify({\"error\": str(e)}), 500",
        "detail": "backend.routes",
        "documentation": {}
    },
    {
        "label": "update_model",
        "kind": 2,
        "importPath": "backend.routes",
        "description": "backend.routes",
        "peekOfCode": "def update_model(id):\n    try:\n        # Query the model by ID\n        model = Model.query.get(id)\n        if model is None:\n            return jsonify({\"error\": \"Model not found\"}), 404\n         # Extract form data and files\n        data = request.form\n        files = request.files\n         # Validation for required fields",
        "detail": "backend.routes",
        "documentation": {}
    },
    {
        "label": "delete_model",
        "kind": 2,
        "importPath": "backend.routes",
        "description": "backend.routes",
        "peekOfCode": "def delete_model(id):\n    try:\n        # Query the model by ID\n        model = Model.query.get(id)\n        if model is None:\n            return jsonify({\"error\": \"Model not found\"}), 404\n        # Extract the file paths from the model\n        model_data = model.to_json()\n        model_filename = model_data.get('filename')\n        scaler_filename = model_data.get('scalerfile')",
        "detail": "backend.routes",
        "documentation": {}
    },
    {
        "label": "predict",
        "kind": 2,
        "importPath": "backend.routes",
        "description": "backend.routes",
        "peekOfCode": "def predict():\n    try:\n        # Retrieve formData and modelId from the request\n        formData = request.json.get(\"formData\")  # Extract formData as a dictionary\n        modelId = request.json.get(\"modelId\")    # Extract modelId as a string or int\n        if not modelId or not formData:\n            return jsonify({\"error\": \"Model ID and form data are required\"}), 400\n        # Retrieve the data record from the database using modelId\n        data_record = Model.query.get(modelId)  # Replace DataModel with your actual model class\n        if not data_record:",
        "detail": "backend.routes",
        "documentation": {}
    },
    {
        "label": "SECRET_PASSWORD",
        "kind": 5,
        "importPath": "backend.routes",
        "description": "backend.routes",
        "peekOfCode": "SECRET_PASSWORD = os.getenv('SECRET_PASSWORD', 'default_password')\ndef check_password(password):\n    return password == SECRET_PASSWORD\ndef require_password(f):\n    @wraps(f)\n    def decorated_function(*args, **kwargs):\n        # Get the password from the form data\n        password = request.form.get('password')\n        print(password)\n        # Check if the password is correct",
        "detail": "backend.routes",
        "documentation": {}
    },
    {
        "label": "_Known",
        "kind": 6,
        "importPath": "frontend.node_modules.flatted.python.flatted",
        "description": "frontend.node_modules.flatted.python.flatted",
        "peekOfCode": "class _Known:\n    def __init__(self):\n        self.key = []\n        self.value = []\nclass _String:\n    def __init__(self, value):\n        self.value = value\ndef _array_keys(value):\n    keys = []\n    i = 0",
        "detail": "frontend.node_modules.flatted.python.flatted",
        "documentation": {}
    },
    {
        "label": "_String",
        "kind": 6,
        "importPath": "frontend.node_modules.flatted.python.flatted",
        "description": "frontend.node_modules.flatted.python.flatted",
        "peekOfCode": "class _String:\n    def __init__(self, value):\n        self.value = value\ndef _array_keys(value):\n    keys = []\n    i = 0\n    for _ in value:\n        keys.append(i)\n        i += 1\n    return keys",
        "detail": "frontend.node_modules.flatted.python.flatted",
        "documentation": {}
    },
    {
        "label": "parse",
        "kind": 2,
        "importPath": "frontend.node_modules.flatted.python.flatted",
        "description": "frontend.node_modules.flatted.python.flatted",
        "peekOfCode": "def parse(value, *args, **kwargs):\n    json = _json.loads(value, *args, **kwargs)\n    wrapped = []\n    for value in json:\n        wrapped.append(_wrap(value))\n    input = []\n    for value in wrapped:\n        if isinstance(value, _String):\n            input.append(value.value)\n        else:",
        "detail": "frontend.node_modules.flatted.python.flatted",
        "documentation": {}
    },
    {
        "label": "stringify",
        "kind": 2,
        "importPath": "frontend.node_modules.flatted.python.flatted",
        "description": "frontend.node_modules.flatted.python.flatted",
        "peekOfCode": "def stringify(value, *args, **kwargs):\n    known = _Known()\n    input = []\n    output = []\n    i = int(_index(known, input, value))\n    while i < len(input):\n        output.append(_transform(known, input, input[i]))\n        i += 1\n    return _json.dumps(output, *args, **kwargs)",
        "detail": "frontend.node_modules.flatted.python.flatted",
        "documentation": {}
    },
    {
        "label": "stringify",
        "kind": 2,
        "importPath": "frontend.node_modules.flatted.python.test",
        "description": "frontend.node_modules.flatted.python.test",
        "peekOfCode": "def stringify(value):\n    return _stringify(value, separators=(',', ':'))\nassert stringify([None, None]) == '[[null,null]]'\na = []\no = {}\nassert stringify(a) == '[[]]'\nassert stringify(o) == '[{}]'\na.append(a)\no['o'] = o\nassert stringify(a) == '[[\"0\"]]'",
        "detail": "frontend.node_modules.flatted.python.test",
        "documentation": {}
    },
    {
        "label": "a",
        "kind": 5,
        "importPath": "frontend.node_modules.flatted.python.test",
        "description": "frontend.node_modules.flatted.python.test",
        "peekOfCode": "a = []\no = {}\nassert stringify(a) == '[[]]'\nassert stringify(o) == '[{}]'\na.append(a)\no['o'] = o\nassert stringify(a) == '[[\"0\"]]'\nassert stringify(o) == '[{\"o\":\"0\"}]'\nb = parse(stringify(a))\nassert isinstance(b, list) and b[0] == b",
        "detail": "frontend.node_modules.flatted.python.test",
        "documentation": {}
    },
    {
        "label": "o",
        "kind": 5,
        "importPath": "frontend.node_modules.flatted.python.test",
        "description": "frontend.node_modules.flatted.python.test",
        "peekOfCode": "o = {}\nassert stringify(a) == '[[]]'\nassert stringify(o) == '[{}]'\na.append(a)\no['o'] = o\nassert stringify(a) == '[[\"0\"]]'\nassert stringify(o) == '[{\"o\":\"0\"}]'\nb = parse(stringify(a))\nassert isinstance(b, list) and b[0] == b\na.append(1)",
        "detail": "frontend.node_modules.flatted.python.test",
        "documentation": {}
    },
    {
        "label": "o['o']",
        "kind": 5,
        "importPath": "frontend.node_modules.flatted.python.test",
        "description": "frontend.node_modules.flatted.python.test",
        "peekOfCode": "o['o'] = o\nassert stringify(a) == '[[\"0\"]]'\nassert stringify(o) == '[{\"o\":\"0\"}]'\nb = parse(stringify(a))\nassert isinstance(b, list) and b[0] == b\na.append(1)\na.append('two')\na.append(True)\no['one'] = 1\no['two'] = 'two'",
        "detail": "frontend.node_modules.flatted.python.test",
        "documentation": {}
    },
    {
        "label": "b",
        "kind": 5,
        "importPath": "frontend.node_modules.flatted.python.test",
        "description": "frontend.node_modules.flatted.python.test",
        "peekOfCode": "b = parse(stringify(a))\nassert isinstance(b, list) and b[0] == b\na.append(1)\na.append('two')\na.append(True)\no['one'] = 1\no['two'] = 'two'\no['three'] = True\nassert stringify(a) == '[[\"0\",1,\"1\",true],\"two\"]'\nassert stringify(o) == '[{\"o\":\"0\",\"one\":1,\"two\":\"1\",\"three\":true},\"two\"]'",
        "detail": "frontend.node_modules.flatted.python.test",
        "documentation": {}
    },
    {
        "label": "o['one']",
        "kind": 5,
        "importPath": "frontend.node_modules.flatted.python.test",
        "description": "frontend.node_modules.flatted.python.test",
        "peekOfCode": "o['one'] = 1\no['two'] = 'two'\no['three'] = True\nassert stringify(a) == '[[\"0\",1,\"1\",true],\"two\"]'\nassert stringify(o) == '[{\"o\":\"0\",\"one\":1,\"two\":\"1\",\"three\":true},\"two\"]'\na.append(o)\no['a'] = a\nassert stringify(a) == '[[\"0\",1,\"1\",true,\"2\"],\"two\",{\"o\":\"2\",\"one\":1,\"two\":\"1\",\"three\":true,\"a\":\"0\"}]'\nassert stringify(o) == '[{\"o\":\"0\",\"one\":1,\"two\":\"1\",\"three\":true,\"a\":\"2\"},\"two\",[\"2\",1,\"1\",true,\"0\"]]'\na.append({'test': 'OK'})",
        "detail": "frontend.node_modules.flatted.python.test",
        "documentation": {}
    },
    {
        "label": "o['two']",
        "kind": 5,
        "importPath": "frontend.node_modules.flatted.python.test",
        "description": "frontend.node_modules.flatted.python.test",
        "peekOfCode": "o['two'] = 'two'\no['three'] = True\nassert stringify(a) == '[[\"0\",1,\"1\",true],\"two\"]'\nassert stringify(o) == '[{\"o\":\"0\",\"one\":1,\"two\":\"1\",\"three\":true},\"two\"]'\na.append(o)\no['a'] = a\nassert stringify(a) == '[[\"0\",1,\"1\",true,\"2\"],\"two\",{\"o\":\"2\",\"one\":1,\"two\":\"1\",\"three\":true,\"a\":\"0\"}]'\nassert stringify(o) == '[{\"o\":\"0\",\"one\":1,\"two\":\"1\",\"three\":true,\"a\":\"2\"},\"two\",[\"2\",1,\"1\",true,\"0\"]]'\na.append({'test': 'OK'})\na.append([1, 2, 3])",
        "detail": "frontend.node_modules.flatted.python.test",
        "documentation": {}
    },
    {
        "label": "o['three']",
        "kind": 5,
        "importPath": "frontend.node_modules.flatted.python.test",
        "description": "frontend.node_modules.flatted.python.test",
        "peekOfCode": "o['three'] = True\nassert stringify(a) == '[[\"0\",1,\"1\",true],\"two\"]'\nassert stringify(o) == '[{\"o\":\"0\",\"one\":1,\"two\":\"1\",\"three\":true},\"two\"]'\na.append(o)\no['a'] = a\nassert stringify(a) == '[[\"0\",1,\"1\",true,\"2\"],\"two\",{\"o\":\"2\",\"one\":1,\"two\":\"1\",\"three\":true,\"a\":\"0\"}]'\nassert stringify(o) == '[{\"o\":\"0\",\"one\":1,\"two\":\"1\",\"three\":true,\"a\":\"2\"},\"two\",[\"2\",1,\"1\",true,\"0\"]]'\na.append({'test': 'OK'})\na.append([1, 2, 3])\no['test'] = {'test': 'OK'}",
        "detail": "frontend.node_modules.flatted.python.test",
        "documentation": {}
    },
    {
        "label": "o['a']",
        "kind": 5,
        "importPath": "frontend.node_modules.flatted.python.test",
        "description": "frontend.node_modules.flatted.python.test",
        "peekOfCode": "o['a'] = a\nassert stringify(a) == '[[\"0\",1,\"1\",true,\"2\"],\"two\",{\"o\":\"2\",\"one\":1,\"two\":\"1\",\"three\":true,\"a\":\"0\"}]'\nassert stringify(o) == '[{\"o\":\"0\",\"one\":1,\"two\":\"1\",\"three\":true,\"a\":\"2\"},\"two\",[\"2\",1,\"1\",true,\"0\"]]'\na.append({'test': 'OK'})\na.append([1, 2, 3])\no['test'] = {'test': 'OK'}\no['array'] = [1, 2, 3]\nassert stringify(a) == '[[\"0\",1,\"1\",true,\"2\",\"3\",\"4\"],\"two\",{\"o\":\"2\",\"one\":1,\"two\":\"1\",\"three\":true,\"a\":\"0\",\"test\":\"3\",\"array\":\"4\"},{\"test\":\"5\"},[1,2,3],\"OK\"]'\nassert stringify(o) == '[{\"o\":\"0\",\"one\":1,\"two\":\"1\",\"three\":true,\"a\":\"2\",\"test\":\"3\",\"array\":\"4\"},\"two\",[\"2\",1,\"1\",true,\"0\",\"3\",\"4\"],{\"test\":\"5\"},[1,2,3],\"OK\"]'\na2 = parse(stringify(a));",
        "detail": "frontend.node_modules.flatted.python.test",
        "documentation": {}
    },
    {
        "label": "o['test']",
        "kind": 5,
        "importPath": "frontend.node_modules.flatted.python.test",
        "description": "frontend.node_modules.flatted.python.test",
        "peekOfCode": "o['test'] = {'test': 'OK'}\no['array'] = [1, 2, 3]\nassert stringify(a) == '[[\"0\",1,\"1\",true,\"2\",\"3\",\"4\"],\"two\",{\"o\":\"2\",\"one\":1,\"two\":\"1\",\"three\":true,\"a\":\"0\",\"test\":\"3\",\"array\":\"4\"},{\"test\":\"5\"},[1,2,3],\"OK\"]'\nassert stringify(o) == '[{\"o\":\"0\",\"one\":1,\"two\":\"1\",\"three\":true,\"a\":\"2\",\"test\":\"3\",\"array\":\"4\"},\"two\",[\"2\",1,\"1\",true,\"0\",\"3\",\"4\"],{\"test\":\"5\"},[1,2,3],\"OK\"]'\na2 = parse(stringify(a));\no2 = parse(stringify(o));\nassert a2[0] == a2\nassert o2['o'] == o2\nassert a2[1] == 1 and a2[2] == 'two' and a2[3] == True and isinstance(a2[4], dict)\nassert a2[4] == a2[4]['o'] and a2 == a2[4]['o']['a']",
        "detail": "frontend.node_modules.flatted.python.test",
        "documentation": {}
    },
    {
        "label": "o['array']",
        "kind": 5,
        "importPath": "frontend.node_modules.flatted.python.test",
        "description": "frontend.node_modules.flatted.python.test",
        "peekOfCode": "o['array'] = [1, 2, 3]\nassert stringify(a) == '[[\"0\",1,\"1\",true,\"2\",\"3\",\"4\"],\"two\",{\"o\":\"2\",\"one\":1,\"two\":\"1\",\"three\":true,\"a\":\"0\",\"test\":\"3\",\"array\":\"4\"},{\"test\":\"5\"},[1,2,3],\"OK\"]'\nassert stringify(o) == '[{\"o\":\"0\",\"one\":1,\"two\":\"1\",\"three\":true,\"a\":\"2\",\"test\":\"3\",\"array\":\"4\"},\"two\",[\"2\",1,\"1\",true,\"0\",\"3\",\"4\"],{\"test\":\"5\"},[1,2,3],\"OK\"]'\na2 = parse(stringify(a));\no2 = parse(stringify(o));\nassert a2[0] == a2\nassert o2['o'] == o2\nassert a2[1] == 1 and a2[2] == 'two' and a2[3] == True and isinstance(a2[4], dict)\nassert a2[4] == a2[4]['o'] and a2 == a2[4]['o']['a']\nstr = parse('[{\"prop\":\"1\",\"a\":\"2\",\"b\":\"3\"},{\"value\":123},[\"4\",\"5\"],{\"e\":\"6\",\"t\":\"7\",\"p\":4},{},{\"b\":\"8\"},\"f\",{\"a\":\"9\"},[\"10\"],\"sup\",{\"a\":1,\"d\":2,\"c\":\"7\",\"z\":\"11\",\"h\":1},{\"g\":2,\"a\":\"7\",\"b\":\"12\",\"f\":6},{\"r\":4,\"u\":\"7\",\"c\":5}]')",
        "detail": "frontend.node_modules.flatted.python.test",
        "documentation": {}
    },
    {
        "label": "a2",
        "kind": 5,
        "importPath": "frontend.node_modules.flatted.python.test",
        "description": "frontend.node_modules.flatted.python.test",
        "peekOfCode": "a2 = parse(stringify(a));\no2 = parse(stringify(o));\nassert a2[0] == a2\nassert o2['o'] == o2\nassert a2[1] == 1 and a2[2] == 'two' and a2[3] == True and isinstance(a2[4], dict)\nassert a2[4] == a2[4]['o'] and a2 == a2[4]['o']['a']\nstr = parse('[{\"prop\":\"1\",\"a\":\"2\",\"b\":\"3\"},{\"value\":123},[\"4\",\"5\"],{\"e\":\"6\",\"t\":\"7\",\"p\":4},{},{\"b\":\"8\"},\"f\",{\"a\":\"9\"},[\"10\"],\"sup\",{\"a\":1,\"d\":2,\"c\":\"7\",\"z\":\"11\",\"h\":1},{\"g\":2,\"a\":\"7\",\"b\":\"12\",\"f\":6},{\"r\":4,\"u\":\"7\",\"c\":5}]')\nassert str['b']['t']['a'] == 'sup' and str['a'][1]['b'][0]['c'] == str['b']['t']\noo = parse('[{\"a\":\"1\",\"b\":\"0\",\"c\":\"2\"},{\"aa\":\"3\"},{\"ca\":\"4\",\"cb\":\"5\",\"cc\":\"6\",\"cd\":\"7\",\"ce\":\"8\",\"cf\":\"9\"},{\"aaa\":\"10\"},{\"caa\":\"4\"},{\"cba\":\"5\"},{\"cca\":\"2\"},{\"cda\":\"4\"},\"value2\",\"value3\",\"value1\"]');\nassert oo['a']['aa']['aaa'] == 'value1' and oo == oo['b'] and oo['c']['ca']['caa'] == oo['c']['ca']",
        "detail": "frontend.node_modules.flatted.python.test",
        "documentation": {}
    },
    {
        "label": "o2",
        "kind": 5,
        "importPath": "frontend.node_modules.flatted.python.test",
        "description": "frontend.node_modules.flatted.python.test",
        "peekOfCode": "o2 = parse(stringify(o));\nassert a2[0] == a2\nassert o2['o'] == o2\nassert a2[1] == 1 and a2[2] == 'two' and a2[3] == True and isinstance(a2[4], dict)\nassert a2[4] == a2[4]['o'] and a2 == a2[4]['o']['a']\nstr = parse('[{\"prop\":\"1\",\"a\":\"2\",\"b\":\"3\"},{\"value\":123},[\"4\",\"5\"],{\"e\":\"6\",\"t\":\"7\",\"p\":4},{},{\"b\":\"8\"},\"f\",{\"a\":\"9\"},[\"10\"],\"sup\",{\"a\":1,\"d\":2,\"c\":\"7\",\"z\":\"11\",\"h\":1},{\"g\":2,\"a\":\"7\",\"b\":\"12\",\"f\":6},{\"r\":4,\"u\":\"7\",\"c\":5}]')\nassert str['b']['t']['a'] == 'sup' and str['a'][1]['b'][0]['c'] == str['b']['t']\noo = parse('[{\"a\":\"1\",\"b\":\"0\",\"c\":\"2\"},{\"aa\":\"3\"},{\"ca\":\"4\",\"cb\":\"5\",\"cc\":\"6\",\"cd\":\"7\",\"ce\":\"8\",\"cf\":\"9\"},{\"aaa\":\"10\"},{\"caa\":\"4\"},{\"cba\":\"5\"},{\"cca\":\"2\"},{\"cda\":\"4\"},\"value2\",\"value3\",\"value1\"]');\nassert oo['a']['aa']['aaa'] == 'value1' and oo == oo['b'] and oo['c']['ca']['caa'] == oo['c']['ca']\nprint('OK')",
        "detail": "frontend.node_modules.flatted.python.test",
        "documentation": {}
    },
    {
        "label": "str",
        "kind": 5,
        "importPath": "frontend.node_modules.flatted.python.test",
        "description": "frontend.node_modules.flatted.python.test",
        "peekOfCode": "str = parse('[{\"prop\":\"1\",\"a\":\"2\",\"b\":\"3\"},{\"value\":123},[\"4\",\"5\"],{\"e\":\"6\",\"t\":\"7\",\"p\":4},{},{\"b\":\"8\"},\"f\",{\"a\":\"9\"},[\"10\"],\"sup\",{\"a\":1,\"d\":2,\"c\":\"7\",\"z\":\"11\",\"h\":1},{\"g\":2,\"a\":\"7\",\"b\":\"12\",\"f\":6},{\"r\":4,\"u\":\"7\",\"c\":5}]')\nassert str['b']['t']['a'] == 'sup' and str['a'][1]['b'][0]['c'] == str['b']['t']\noo = parse('[{\"a\":\"1\",\"b\":\"0\",\"c\":\"2\"},{\"aa\":\"3\"},{\"ca\":\"4\",\"cb\":\"5\",\"cc\":\"6\",\"cd\":\"7\",\"ce\":\"8\",\"cf\":\"9\"},{\"aaa\":\"10\"},{\"caa\":\"4\"},{\"cba\":\"5\"},{\"cca\":\"2\"},{\"cda\":\"4\"},\"value2\",\"value3\",\"value1\"]');\nassert oo['a']['aa']['aaa'] == 'value1' and oo == oo['b'] and oo['c']['ca']['caa'] == oo['c']['ca']\nprint('OK')",
        "detail": "frontend.node_modules.flatted.python.test",
        "documentation": {}
    },
    {
        "label": "oo",
        "kind": 5,
        "importPath": "frontend.node_modules.flatted.python.test",
        "description": "frontend.node_modules.flatted.python.test",
        "peekOfCode": "oo = parse('[{\"a\":\"1\",\"b\":\"0\",\"c\":\"2\"},{\"aa\":\"3\"},{\"ca\":\"4\",\"cb\":\"5\",\"cc\":\"6\",\"cd\":\"7\",\"ce\":\"8\",\"cf\":\"9\"},{\"aaa\":\"10\"},{\"caa\":\"4\"},{\"cba\":\"5\"},{\"cca\":\"2\"},{\"cda\":\"4\"},\"value2\",\"value3\",\"value1\"]');\nassert oo['a']['aa']['aaa'] == 'value1' and oo == oo['b'] and oo['c']['ca']['caa'] == oo['c']['ca']\nprint('OK')",
        "detail": "frontend.node_modules.flatted.python.test",
        "documentation": {}
    }
]